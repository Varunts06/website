<h1><center>Glue and coprocessor architectures</center></h1><hr size="5" color="grey"><a href="blockchain.html">Blockchains</a>
<a href="economics.html" style="float: right;">Economics</a>
<center><a href="cryptography.html">Cryptography</a></center>
<a href="General.html">General</a>
<a href="gitcoin.html" style="float: right;">Gitcoin</a>
<center><a href="math.html">math</a></center>
<hr size="5" color="grey">
<a href="front.html" style="float: right;">see all posts</a><br>
<p>If you analyze any resource-intensive computation being done in the modern world in even a medium amount of detail, one feature that you will find again and again is that the computation can be broken up into two parts:</p>
<ol>
    <li>A relatively small amount of complex, but not very computationally intensive,<b>"business logic"</b> </li>
    <li>A large amount of intensive, but highly structured, <b>"expensive work"</b> </li>
    
</ol>
<p>These two forms of computation are best handled in different ways: the former, with an architecture that may have lower efficiency but needs to have very high generality, and the latter, with an architecture that may have lower generality, but needs to have very high efficiency.</p>
<h3>What are some examples of this separation in practice?</h3><hr>
<p>To start off, let us look under the hood of the environment I am most familiar with: the <b>Ethereum Virtual Machine (EVM)</b> . Here is the geth debug trace of a recent Ethereum transaction that I did: updating the IPFS hash of my blog on ENS. The transaction consumes a total of 46924 gas, which can be categorized in this way:</p>
<ul>
    <li>Base cost: 21,000</li>
      <li>Calldata: 1,556</li>  
      <li> EVM execution: 24,368</li> 
      <li> SLOAD opcode: 6,400</li> 
      <li> SSTORE opcode: 10,100</li> 
      <li>LOG opcode: 2,149</li>  
       <li> Other: 6,719</li>
</ul>
<p>The moral of the story is: <b> most of the execution</b> (~73% if you look at the EVM alone, ~85% if you include the portion of the base cost that covers computation) is concentrated in a <b>very small number of structured expensive operations</b>: storage reads and writes, logs, and cryptography (the base cost includes 3000 to pay for signature verification, and the EVM also includes 272 to pay for hashing). <b>The rest of the execution is "business logic"</b>: fiddling around with the bits of the calldata to extract the ID of the record I am trying to set and the hash I am setting it to, and so on. In a token transfer, this would include adding and subtracting balances, in a more advanced application, this might include a loop, and so on.</p>
<p>In the EVM, these two forms of execution are handled in different ways. The high-level business logic is written in a higher-level language, often Solidity, which compiles to the EVM. The expensive work is still triggered by EVM opcodes (SLOAD, etc), but > 99% of the actual computation is done in specialized modules written directly inside of client code (or even libraries).</p>
<p>Just like in the EVM example, the two types of work are handled in two different ways. The high-level business logic code is written in Python, a highly general and flexible language which is also very slow, and we just accept the inefficiency because it only touches a small part of the total computational cost. Meanwhile, the intensive operations are written in highly optimized code, often CUDA code running on a GPU. Increasingly, we're even starting to see LLM inference being done on ASICs.</p>
<p>To see how this works, we can look at one of the latest trends in STARK proving. To be general-purpose and easy to use, teams are increasingly building STARK provers for widely-adopted minimal virtual machines, such as RISC-V. Any program whose execution needs to be proven can be compiled into RISC-V, and then the prover can prove the RISC-V execution of that code.

</p>